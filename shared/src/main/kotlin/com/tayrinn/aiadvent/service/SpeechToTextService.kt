package com.tayrinn.aiadvent.service

import com.tayrinn.aiadvent.data.api.HuggingFaceApi
import com.tayrinn.aiadvent.data.api.createHuggingFaceApi
import com.tayrinn.aiadvent.data.model.WhisperResponse
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import kotlinx.serialization.json.Json
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.MultipartBody
import okhttp3.RequestBody.Companion.toRequestBody
import java.io.ByteArrayOutputStream
import javax.sound.sampled.*

/**
 * –°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é Hugging Face Whisper –º–æ–¥–µ–ª–∏
 */
class SpeechToTextService(
    private val huggingFaceApi: HuggingFaceApi = createHuggingFaceApi()
) {
    private val json = Json { ignoreUnknownKeys = true }

    /**
     * –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –≤ —Ç–µ—á–µ–Ω–∏–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
     */
    suspend fun recordAudio(durationSeconds: Int = 5): ByteArray = withContext(Dispatchers.IO) {
        val format = AudioFormat(16000f, 16, 1, true, false) // 16kHz, 16-bit, mono
        val info = DataLine.Info(TargetDataLine::class.java, format)

        if (!AudioSystem.isLineSupported(info)) {
            throw Exception("–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
        }

        val line = AudioSystem.getLine(info) as TargetDataLine
        line.open(format)
        line.start()

        val bufferSize = 1024
        val buffer = ByteArray(bufferSize)
        val outputStream = ByteArrayOutputStream()

        println("üé§ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ ($durationSeconds —Å–µ–∫)...")

        val startTime = System.currentTimeMillis()
        while (System.currentTimeMillis() - startTime < durationSeconds * 1000) {
            val bytesRead = line.read(buffer, 0, bufferSize)
            outputStream.write(buffer, 0, bytesRead)
        }

        line.stop()
        line.close()

        val audioData = outputStream.toByteArray()
        println("‚úÖ –ó–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä: ${audioData.size} –±–∞–π—Ç")

        audioData
    }

    /**
     * –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –≤ WAV —Ñ–æ—Ä–º–∞—Ç
     */
    private fun convertToWav(pcmData: ByteArray, sampleRate: Int = 16000): ByteArray {
        val outputStream = ByteArrayOutputStream()

        // WAV header
        outputStream.write("RIFF".toByteArray())
        val fileSize = 36 + pcmData.size
        outputStream.write(byteArrayOf(
            (fileSize and 0xFF).toByte(),
            ((fileSize shr 8) and 0xFF).toByte(),
            ((fileSize shr 16) and 0xFF).toByte(),
            ((fileSize shr 24) and 0xFF).toByte()
        ))
        outputStream.write("WAVE".toByteArray())
        outputStream.write("fmt ".toByteArray())
        outputStream.write(byteArrayOf(16, 0, 0, 0)) // Subchunk1Size
        outputStream.write(byteArrayOf(1, 0)) // AudioFormat (PCM)
        outputStream.write(byteArrayOf(1, 0)) // NumChannels (mono)
        outputStream.write(byteArrayOf(
            (sampleRate and 0xFF).toByte(),
            ((sampleRate shr 8) and 0xFF).toByte(),
            ((sampleRate shr 16) and 0xFF).toByte(),
            ((sampleRate shr 24) and 0xFF).toByte()
        ))
        val byteRate = sampleRate * 2 // SampleRate * NumChannels * BitsPerSample/8
        outputStream.write(byteArrayOf(
            (byteRate and 0xFF).toByte(),
            ((byteRate shr 8) and 0xFF).toByte(),
            ((byteRate shr 16) and 0xFF).toByte(),
            ((byteRate shr 24) and 0xFF).toByte()
        ))
        outputStream.write(byteArrayOf(2, 0)) // BlockAlign
        outputStream.write(byteArrayOf(16, 0)) // BitsPerSample
        outputStream.write("data".toByteArray())
        outputStream.write(byteArrayOf(
            (pcmData.size and 0xFF).toByte(),
            ((pcmData.size shr 8) and 0xFF).toByte(),
            ((pcmData.size shr 16) and 0xFF).toByte(),
            ((pcmData.size shr 24) and 0xFF).toByte()
        ))
        outputStream.write(pcmData)

        return outputStream.toByteArray()
    }

    /**
     * –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Hugging Face Whisper
     */
    suspend fun transcribeAudio(audioData: ByteArray): String = withContext(Dispatchers.IO) {
        try {
            println("üéØ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...")

            val wavData = convertToWav(audioData)

            val response = huggingFaceApi.transcribeAudio(wavData)

            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                if (responseBody != null) {
                    val whisperResponse = json.decodeFromString<WhisperResponse>(responseBody)
                    val text = whisperResponse.text.trim()
                    println("‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: \"$text\"")
                    return@withContext text
                } else {
                    throw Exception("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API")
                }
            } else {
                throw Exception("–û—à–∏–±–∫–∞ API: ${response.code} - ${response.message}")
            }
        } catch (e: Exception) {
            println("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: ${e.message}")
            throw e
        }
    }

    /**
     * –ü–æ–ª–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø–∏—Å–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
     */
    suspend fun recordAndTranscribe(durationSeconds: Int = 5): String {
        val audioData = recordAudio(durationSeconds)
        return transcribeAudio(audioData)
    }
}
